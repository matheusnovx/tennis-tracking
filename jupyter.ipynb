{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import feature\n",
    "from imutils import paths\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "# Path to the dataset and cell size for HOG\n",
    "datapath = \"/home/novais/Documents/tennis-tracking/frames\"\n",
    "cell_size = 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define HOG Feature Extraction Function\n",
    "def quantify_image_HoG(image, cell_size=12):\n",
    "    features = feature.hog(image, orientations=9, \n",
    "                           pixels_per_cell=(cell_size, cell_size),\n",
    "                           cells_per_block=(2, 2),\n",
    "                           transform_sqrt=True, block_norm=\"L1\")\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "def load_dataset(datasetPath, cell_size=12):\n",
    "    imagePaths = list(paths.list_images(datasetPath))\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for imagePath in imagePaths:\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (200, 200))\n",
    "        image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "        features = quantify_image_HoG(image, cell_size)\n",
    "        data.append(features)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "print(\"[INFO] loading data...\")\n",
    "data, labels = load_dataset(datapath, cell_size)\n",
    "\n",
    "# Check the distribution of classes\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(f\"[INFO] class distribution: {class_distribution}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Save Model\n",
    "def train_and_save_model(data, labels, model_path='model.pickle', le_path='label_encoder.pickle'):\n",
    "    # Encode the labels\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(labels)\n",
    "\n",
    "    # Check if we have at least two classes\n",
    "    if len(np.unique(labels)) < 2:\n",
    "        raise ValueError(\"The dataset must contain at least two classes.\")\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    (trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    # Train the classifier\n",
    "    print(\"[INFO] training classifier...\")\n",
    "    model = LinearSVC()\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    print(\"[INFO] evaluating classifier...\")\n",
    "    predictions = model.predict(testX)\n",
    "    print(classification_report(testY, predictions, target_names=le.classes_))\n",
    "\n",
    "    # Save the model and label encoder\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    with open(le_path, 'wb') as f:\n",
    "        pickle.dump(le, f)\n",
    "\n",
    "# Train the model and save it\n",
    "train_and_save_model(data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background Subtractor for Player Detection\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Define Player Detection Functions\n",
    "def process_frame(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    gray_blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply background subtraction\n",
    "    fg_mask = background_subtractor.apply(gray_blurred)\n",
    "    \n",
    "    # Apply morphological operations to clean the mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter contours by area size to focus on players\n",
    "    player_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 500]  # Adjust the threshold as needed\n",
    "    \n",
    "    return player_contours\n",
    "\n",
    "def draw_players(player_contours, frame):\n",
    "    for contour in player_contours:\n",
    "        # Get the bounding box for each player contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Draw the detected player\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background Subtractor for Player Detection\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Define Player Detection Functions\n",
    "def process_frame(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    gray_blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply background subtraction\n",
    "    fg_mask = background_subtractor.apply(gray_blurred)\n",
    "    \n",
    "    # Apply morphological operations to clean the mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter contours by area size to focus on players\n",
    "    player_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 500]  # Adjust the threshold as needed\n",
    "    \n",
    "    return player_contours\n",
    "\n",
    "def draw_players(player_contours, frame):\n",
    "    for contour in player_contours:\n",
    "        # Get the bounding box for each player contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Draw the detected player\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Video to Detect Tennis Court and Players in Each Frame\n",
    "def process_video(videoPath):\n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    for i in range(frame_count):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if is_tennis_court(frame):\n",
    "            print(f\"Frame {i+1}: Tennis court detected.\")\n",
    "            player_contours = process_frame(frame)\n",
    "            frame_with_players = draw_players(player_contours, frame)\n",
    "            cv2.imshow('Player Detection', frame_with_players)\n",
    "        else:\n",
    "            print(f\"Frame {i+1}: No tennis court detected.\")\n",
    "            cv2.imshow('Player Detection', frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == ord('p'):\n",
    "            cv2.waitKey(-1) #wait until any key is pressed\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the input video\n",
    "video_path = 'tennis_match2.mp4'\n",
    "\n",
    "# Process the video\n",
    "process_video(video_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
